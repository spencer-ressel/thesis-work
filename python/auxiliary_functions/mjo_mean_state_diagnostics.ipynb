{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d40e722b-5270-4a68-a9e8-7082dc5f9f16",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "\n",
    "**Authors:** Mu-Ting Chien & Spencer Ressel\n",
    "\n",
    "**Created:** June 25th, 2020\n",
    "\n",
    "This jupyter notebook contains a multitude of functions useful for analyzing geospatial data relevant to the Madden-Julian Oscillation (MJO). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b150d38b-f4c6-4392-ae43-c43a29f853b5",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "333f88d3-179b-4501-ab14-42a9d36e669c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110dd968-ebe9-4019-9d36-5c8daaa90019",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256807bc-9d0c-4679-ad8b-540471c8f908",
   "metadata": {},
   "source": [
    "## Basic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "076583eb-03e9-4bcd-b322-e91e1c8bdb9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inpaint_nans(x, critical_val, big_or_small):  # assume x is 3-dim, assume nan is the same in time\n",
    "    \"\"\"\n",
    "    Basics: remove nan, calculate anomaly, transform time format(yyyymmdd to year_month_day), \n",
    "           select seasons, meridional average\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if big_or_small == 1:  # >critical value-->nan\n",
    "        i = np.squeeze(np.argwhere(x[1, :, :] > critical_val))\n",
    "        # print(i)\n",
    "        print(np.shape(i))\n",
    "    elif big_or_small == 0:  # <critical value-->nan\n",
    "        i = np.squeeze(np.argwhere(x[1, :, :] < critical_val))\n",
    "    elif big_or_small == -1:\n",
    "        i = np.squeeze(np.argwhere(np.isnan(x) == 1))\n",
    "        print(i)\n",
    "        print(np.shape(i))\n",
    "    if np.sum(i) == 0:\n",
    "        print(\"no nan data\")\n",
    "        x_nonan = x\n",
    "    else:\n",
    "        print(\"has nan data!!!\")\n",
    "        nansize = np.size(i, 0)\n",
    "        a = np.empty([np.size(x, 0), nansize])\n",
    "        a[:] = np.nan\n",
    "        x_nonan = x\n",
    "        # x_nonan[i[:,0],i[:,1],i[:,2]] = a\n",
    "        x_nonan[:, i[:, 0], i[:, 1]] = a\n",
    "\n",
    "        for j in range(0, 1):  # nansize):\n",
    "            # j0 = i[j,0]\n",
    "            j1 = i[j, 0]  # [j,1]\n",
    "            j2 = i[j, 1]  # [j,2]\n",
    "\n",
    "            \"\"\"\n",
    "            if j0 ==0:\n",
    "                J0L = np.nan\n",
    "            else:\n",
    "                J0L = x_nonan[j0-1,j1,j2]\n",
    "                \n",
    "            if j0 == np.size(x_nonan,0)-1:\n",
    "                J0R = np.nan\n",
    "            else:\n",
    "                J0R = x_nonan[j0+1,j1,j2]\n",
    "            \"\"\"\n",
    "            if j1 == 0:\n",
    "                J1L = np.empty([np.size(x, 0)])\n",
    "                J1L[:] = np.nan\n",
    "            else:\n",
    "                # J1L = x_nonan[j0,j1-1,j2]\n",
    "                J1L = x_nonan[:, j1 - 1, j2]\n",
    "            if j1 == np.size(x_nonan, 1) - 1:\n",
    "                J1R = np.empty([np.size(x, 0)])\n",
    "                J1R[:] = np.nan\n",
    "            else:\n",
    "                # J1R = x_nonan[j0,j1+1,j2]\n",
    "                J1R = x_nonan[:, j1 + 1, j2]\n",
    "            if j2 == 0:\n",
    "                J2L = np.empty([np.size(x, 0)])\n",
    "                J2L[:] = np.nan\n",
    "            else:\n",
    "                # J2L = x_nonan[j0,j1,j2-1]\n",
    "                J2L = x_nonan[:, j1, j2 - 1]\n",
    "            if j2 == np.size(x_nonan, 2) - 1:\n",
    "                J2R = np.nan([np.size(x, 0)])\n",
    "            else:\n",
    "                J2R = np.empty([np.size(x, 0)])\n",
    "                J2R[:] = np.nan\n",
    "            # x_nonan[j0,j1,j2] = np.nanmean(np.array([J0L,J0R,J1L,J1R,J2L,J2R]))\n",
    "            # for k in range(0,np.size(x,0)):\n",
    "            x_nonan[:, j1, j2] = np.nanmean(np.array([J1L, J1R, J2L, J2R]), 0)\n",
    "            print(J1L)\n",
    "            print(J1R)\n",
    "            print(J2L)\n",
    "            print(J2R)\n",
    "            print(x_nonan[:, j1, j2])\n",
    "    return x_nonan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0ee09ce-37cb-420f-aaff-b53f344f67c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inpaint_nans_2(\n",
    "    x, critical_val, big_or_small\n",
    "):  # assume x is 3-dim, assume nan is the same in time dimension\n",
    "    if big_or_small == 1:  # >critical value-->nan\n",
    "        x = np.where(x > critical_val, np.nan, x)\n",
    "    elif big_or_small == 0:  # <critical value-->nan\n",
    "        x = np.where(x < critical_val, np.nan, x)\n",
    "    i = np.argwhere(np.isnan(x[1, :, :]) == 1)\n",
    "    # print(np.shape(i))\n",
    "    print(\n",
    "        \"portion of nan data:\" + str(np.size(i, 0) / ((np.size(x, 1) * np.size(x, 2))))\n",
    "    )\n",
    "    if np.sum(np.shape(i)) == 0:\n",
    "        print(\"no nan data\")\n",
    "        x_nonan = x\n",
    "    else:\n",
    "        print(\"has nan data!!!\")\n",
    "        nansize = np.size(i, 0)\n",
    "        x_nonan = x\n",
    "\n",
    "        for j in range(0, nansize):\n",
    "            j1 = i[j, 0]  # [j,1]\n",
    "            j2 = i[j, 1]  # [j,2]\n",
    "            if j1 == 0:\n",
    "                J1L = np.empty([np.size(x, 0)])\n",
    "                J1L[:] = np.nan\n",
    "            else:\n",
    "                J1L = x_nonan[:, j1 - 1, j2]\n",
    "            if j1 == np.size(x_nonan, 1) - 1:\n",
    "                J1R = np.empty([np.size(x, 0)])\n",
    "                J1R[:] = np.nan\n",
    "            else:\n",
    "                J1R = x_nonan[:, j1 + 1, j2]\n",
    "            if j2 == 0:\n",
    "                J2L = np.empty([np.size(x, 0)])\n",
    "                J2L[:] = np.nan\n",
    "            else:\n",
    "                J2L = x_nonan[:, j1, j2 - 1]\n",
    "            if j2 == np.size(x_nonan, 2) - 1:\n",
    "                J2R = np.empty([np.size(x, 0)])\n",
    "                J2R[:] = np.nan\n",
    "            else:\n",
    "                J2R = x_nonan[:, j1, j2 + 1]\n",
    "            x_nonan[:, j1, j2] = np.nanmean(np.array([J1L, J1R, J2L, J2R]), 0)\n",
    "    print(np.argwhere(np.isnan(x_nonan) == 1))\n",
    "    return x_nonan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44a2aeeb-488f-4e23-b91c-ddcc994df0d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inpaint_nans_3(\n",
    "    x, critical_val, big_or_small\n",
    "):  # assume x is 3-dim, assume nan is the same in time dimension\n",
    "    if big_or_small == 1:  # >critical value-->nan\n",
    "        x = np.where(x > critical_val, np.nan, x)\n",
    "    elif big_or_small == 0:  # <critical value-->nan\n",
    "        x = np.where(x < critical_val, np.nan, x)\n",
    "    x_nonan = x\n",
    "    if np.sum(np.shape(np.argwhere(np.isnan(x) == 1))) == 0:\n",
    "        print(\"no nan data\")\n",
    "    else:\n",
    "        print(\"has nan data!!!\")\n",
    "        for t in range(0, np.size(x, 0)):\n",
    "            i = np.argwhere(np.isnan(x[t, :, :]) == 1)\n",
    "            # print(np.shape(i))\n",
    "            if t == 0:\n",
    "                print(\n",
    "                    \"portion of nan data:\"\n",
    "                    + str(np.size(i, 0) / ((np.size(x, 1) * np.size(x, 2))))\n",
    "                )\n",
    "            nansize = np.size(i, 0)\n",
    "\n",
    "            for j in range(0, nansize):\n",
    "                j1 = i[j, 0]  # [j,1]\n",
    "                j2 = i[j, 1]  # [j,2]\n",
    "                if j1 == 0:\n",
    "                    # J1L = np.empty([np.size(x,0)])\n",
    "                    J1L = np.nan\n",
    "                else:\n",
    "                    J1L = x_nonan[t, j1 - 1, j2]\n",
    "                if j1 == np.size(x, 1) - 1:\n",
    "                    # J1R = np.empty([np.size(x,0)])\n",
    "                    J1R = np.nan\n",
    "                else:\n",
    "                    J1R = x_nonan[t, j1 + 1, j2]\n",
    "                if j2 == 0:\n",
    "                    # J2L = np.empty([np.size(x,0)])\n",
    "                    J2L = np.nan\n",
    "                else:\n",
    "                    J2L = x_nonan[t, j1, j2 - 1]\n",
    "                if j2 == np.size(x, 2) - 1:\n",
    "                    # J2R = np.empty([np.size(x,0)])\n",
    "                    J2R = np.nan\n",
    "                else:\n",
    "                    J2R = x_nonan[t, j1, j2 + 1]\n",
    "                x_nonan[t, j1, j2] = np.nanmean(np.array([J1L, J1R, J2L, J2R]))\n",
    "                if np.isnan(x_nonan[t, j1, j2]) == 1:\n",
    "                    print(\"t=\" + str(t))\n",
    "                    print(\"j1=\" + str(j1))\n",
    "                    print(\"j2=\" + str(j2))\n",
    "            if len(np.argwhere(np.isnan(x_nonan) == 1)) == 0:\n",
    "                print(\"succesfully inpaint nan\")\n",
    "    # print(np.argwhere(np.isnan(x_nonan)==1))\n",
    "    return x_nonan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2d19305-2996-4354-be63-af54c456fc10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filled_to_nan(x, critical_val, big_or_small):\n",
    "\n",
    "    if big_or_small == 1:  # >critical value-->nan\n",
    "        x_nan = np.where(x > critical_val, np.nan, x)\n",
    "    elif big_or_small == 0:  # <critical value-->nan\n",
    "        x_nan = np.where(x < critical_val, np.nan, x)\n",
    "    if np.sum(np.isnan(x_nan)) == 0:\n",
    "        pass\n",
    "        # print('Checking for nan data')\n",
    "        # print('======================')\n",
    "    else:\n",
    "        print(\"Signal has nan data!!!\")\n",
    "    return x_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71af258a-7f6e-4c45-9da2-dcd662c65291",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_annual_cycle(data, n_harmonics=3):\n",
    "    \"\"\"\n",
    "    This function removes the annual cycle and it's first n harmonics from a given signal. \n",
    "    Note: The first dimension must be time. The number and order of other dimensions is arbitrary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : xarray.core.dataarray.DataArray\n",
    "        An array containing gridded data from which to remove the annual cycle.\n",
    "    n_harmonics: int, (default 3.0)\n",
    "        An integer specifying the number of harmonics to be removed from the signal\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data_deannualized : xarray.core.dataarray.DataArray\n",
    "        An array containing the processed signal with the annual cycle removed.\n",
    "    annual_cycle : xarray.core.dataarray.DataArray\n",
    "        An array containing the signal of the annual cycle that was removed.\n",
    "\n",
    "    \"\"\"\n",
    "    # mmax = 7  # (7-1)/2= 3; remove mean and first 3 harmonics\n",
    "    mmax = 2*n_harmonics+1\n",
    "    harmonics = np.arange(1, n_harmonics+1)\n",
    "\n",
    "    # Length of the time axis\n",
    "    n_times = np.size(data, axis=0)\n",
    "\n",
    "    # An array increasing over the time axis\n",
    "    t = np.arange(1, n_times + 1, 1)\n",
    "\n",
    "    # Arrays specifying the odd and even columns of the matrix A\n",
    "    odds = np.arange(1, mmax, 2)\n",
    "    evens = np.arange(2, mmax + 1, 2)\n",
    "    \n",
    "    # The matrix A has a shape that depends on the shape of the input data\n",
    "    A = np.ones([mmax, n_times])\n",
    "\n",
    "    # Specify the odd columns of A\n",
    "    A[odds] = np.cos(2*np.pi*harmonics[:, np.newaxis]*t[np.newaxis, :]/365)\n",
    "\n",
    "    # Specify the even columns of A\n",
    "    A[evens] = np.sin(2*np.pi*harmonics[:, np.newaxis]*t[np.newaxis, :]/365)\n",
    "\n",
    "    # Matrix multiplication of the A matrix and the input data\n",
    "    C = np.einsum(\"ij, j...->i...\", A, data)/n_times\n",
    "\n",
    "    # Calculate the annual cycle\n",
    "    annual_cycle = np.einsum(\"ij,i...->j...\", A, C)\n",
    "\n",
    "    # Remove the annual cycle from the input data\n",
    "    data_deannualized = data - annual_cycle\n",
    "        \n",
    "    return data_deannualized, annual_cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34026178-692c-45df-8466-8121e60f4219",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mean_var(x, x_ano, x_f):  # caution: assume time in the 0th direction\n",
    "    # Calculate mean of original data, variance of anomaly/filtered data\n",
    "    # if dim == 3:\n",
    "    x_m = np.nanmean(x, 0)  # mean\n",
    "    # if dim == 4:\n",
    "    # x_m = np.mean(x[:,ilev,:,:],0) # mean\n",
    "    x_av = np.nanvar(x_ano, 0)  # variance of anomaly\n",
    "    x_fv = np.nanvar(x_f, 0)  # variance of intraseasonal signal\n",
    "    return x_m, x_av, x_fv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6830e73d-2112-4a61-974c-144f5f179079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def yyyymmdd_y_m_d(dates):  # transfer yyyymmdd into year mon day (3 matrix)\n",
    "    year = np.zeros(np.size(dates))\n",
    "    mon = np.zeros(np.size(dates))\n",
    "    day = np.zeros(np.size(dates))\n",
    "    for i in range(0, np.size(dates)):\n",
    "        time_str = str(dates[i])  # original format of time is yyyymmdd\n",
    "        year[i] = int(time_str[0:4])\n",
    "        mon[i] = int(time_str[4:6])\n",
    "        day[i] = int(time_str[6:8])\n",
    "    return year, mon, day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff34d614-9972-4dff-8a0a-4c7980b6fd39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def yyyymmdd_to_datetime64(dates):\n",
    "    from datetime import datetime\n",
    "\n",
    "    year = np.zeros(np.size(dates), dtype=int)\n",
    "    month = np.zeros(np.size(dates), dtype=int)\n",
    "    day = np.zeros(np.size(dates), dtype=int)\n",
    "    dates_long = []\n",
    "    for i in range(0, np.size(dates)):\n",
    "        time_str = str(dates[i])  # original format of time is yyyymmdd\n",
    "        year[i] = int(time_str[0:4])\n",
    "        month[i] = int(time_str[4:6])\n",
    "        day[i] = int(time_str[6:8])\n",
    "        dates_long.append(np.datetime64(datetime(year[i], month[i], day[i])))\n",
    "    return np.array(dates_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea389ded-0a0e-436b-a9f9-4569074e2c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def datetime64_to_yyyymmdd(dates):\n",
    "    int_dates = np.zeros(np.size(dates), dtype=int)\n",
    "\n",
    "    for i in range(0, np.size(dates)):\n",
    "        int_dates[i] = int(\n",
    "            dates[i].astype(str)[0:4]\n",
    "            + dates[i].astype(str)[5:7]\n",
    "            + dates[i].astype(str)[8:10]\n",
    "        )\n",
    "    return int_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4d45bf4-21c7-4f78-8710-faa00a3b273d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mer_ave(x, lat, latdim):  # assume x is (time,lat,lon)\n",
    "    cos_lat = np.cos(np.deg2rad(lat))\n",
    "    if np.sum(np.isnan(x) == 1) == 0:  # no nan\n",
    "        x_mer_ave = np.average(x, latdim, weights=cos_lat)\n",
    "    else:  # is nan\n",
    "        print(\"has nan, but use nanmean\")\n",
    "        nt = np.size(x, 0)\n",
    "        nlon = np.size(x, 2)\n",
    "        nlat = np.size(x, 1)\n",
    "        x_mer_ave = np.empty((nt, nlon))\n",
    "        x_mer_ave[:] = np.nan\n",
    "        for it in range(0, nt):\n",
    "            for ilon in range(0, nlon):\n",
    "                x2 = x[it, :, ilon]\n",
    "                indices = ~np.isnan(x2)\n",
    "                x_mer_ave[it, ilon] = np.average(x2[indices], weights=cos_lat[indices])\n",
    "    return x_mer_ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a694889-aebb-486a-b56e-6f44852a2a3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mer_ave_2d(x, lat):  # assume x is (lat,lon)\n",
    "    cos_lat = np.cos(np.deg2rad(lat))\n",
    "    if np.sum(np.isnan(x) == 1) == 0:\n",
    "        x_mer_ave = np.average(x, 0, weights=cos_lat)\n",
    "    else:\n",
    "        print(\"has nan, but use nanmean\")\n",
    "        nlon = np.size(x, 1)\n",
    "        nlat = np.size(x, 0)\n",
    "        if np.size(np.shape(x)) == 3:\n",
    "            nt = np.size(x, 2)\n",
    "            x_mer_ave = np.empty((nlon, nt))\n",
    "        else:\n",
    "            nt = 1\n",
    "            x_mer_ave = np.empty((nlon))\n",
    "        x_mer_ave[:] = np.nan\n",
    "        for it in range(0, nt):\n",
    "            for ilon in range(0, nlon):\n",
    "                if nt != 1:\n",
    "                    x2 = x[:, ilon, it]\n",
    "                else:\n",
    "                    x2 = x[:, ilon]\n",
    "                indices = ~np.isnan(x2)\n",
    "                if nt == 1:\n",
    "                    x_mer_ave[ilon] = np.average(x2[indices], weights=cos_lat[indices])\n",
    "                else:\n",
    "                    x_mer_ave[ilon, it] = np.average(\n",
    "                        x2[indices], weights=cos_lat[indices]\n",
    "                    )\n",
    "    return x_mer_ave"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c358eec1-3ee4-4e7a-88c9-32b487edb40e",
   "metadata": {},
   "source": [
    "## Filtering Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3e70d03-3109-4772-8ec2-c3511bf41690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype=\"band\")\n",
    "    return b, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1584f5d6-23aa-42aa-bf6d-55931c1283e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da33a628-e248-479f-bd89-e8350adca6dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def butter_highpass(cut, fs, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    cut = cut / nyq\n",
    "    b, a = butter(order, cut, btype=\"highpass\")\n",
    "    return b, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27df95c2-89ec-47c1-8888-3d45df023308",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def butter_highpass_filter(data, cut, fs, order=5):\n",
    "    b, a = butter_highpass(cut, fs, order=order)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1fb7cdb-7431-4caa-8e7c-e1c4f8fd9b7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def butter_lowpass(cut, fs, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    cut = cut / nyq\n",
    "    b, a = butter(order, cut, btype=\"lowpass\")\n",
    "    return b, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f959468-4015-442c-bc61-57a909bca9e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def butter_lowpass_filter(data, cut, fs, order=5):\n",
    "    b, a = butter_lowpass(cut, fs, order=order)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "039febc0-d465-4a14-83bf-91212a5fa3e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lanczos_lowpass_filter(data, cut, fs, order=101):\n",
    "    \"\"\"\n",
    "    This function returns a filtered signal in which all frqeuencies above the \n",
    "    cut-off have been attenuated. This is done using a Lanczos filter. The \n",
    "    filter works on any dimensional data, as long as the filtering dimension\n",
    "    is along axis=-1.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : numpy.ndarray\n",
    "        The data to be filtered.\n",
    "    cut : float\n",
    "        The frequency cut-off. All frequencies above 'cut' are attenuated.\n",
    "    fs : float\n",
    "        The sampling frequency of the data.\n",
    "    order : int\n",
    "        The number of weights to use in the Lanczos filter. Must be odd.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data_filtered : numpy.ndarray\n",
    "        The filtered data.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # 2n-1 total weights\n",
    "    n = int((order + 1) / 2)\n",
    "\n",
    "    # Define the nyquist frequency\n",
    "    nyq = 0.5 * fs\n",
    "\n",
    "    # Define the range of the filter\n",
    "    k = np.arange(1, n, 1)\n",
    "\n",
    "    # Calculate the Lanczos sigma factor\n",
    "    sigma = np.empty((order))\n",
    "    sigma[n:] = np.sinc(2 * k * nyq * fs / n)\n",
    "    sigma[: n - 1] = np.sinc(2 * k[::-1] * nyq * fs / n)\n",
    "    sigma[n - 1] = np.sinc(0)\n",
    "\n",
    "    # Calculate the ideal response factor\n",
    "    w = np.empty((order))\n",
    "    w[n:] = np.sin(2.0 * np.pi * cut * k) / (np.pi * k)\n",
    "    w[: n - 1] = np.sin(2.0 * np.pi * cut * k[::-1]) / (np.pi * k[::-1])\n",
    "    w[n - 1] = 2 * cut\n",
    "\n",
    "    # Combine the effects of the ideal response factor and the Lanczos factor\n",
    "    w_bar = w * sigma\n",
    "\n",
    "    # Filter the data along axis=-1\n",
    "    data_filtered = np.apply_along_axis(\n",
    "        lambda m: np.convolve(m, w_bar, mode=\"same\"), axis=-1, arr=data\n",
    "    )\n",
    "\n",
    "    return data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fda89dc8-8f18-471e-bb50-b6adb95221e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lanczos_highpass_filter(data, cut, fs, order=101):\n",
    "    \"\"\"\n",
    "    This function returns a filtered signal in which all frqeuencies below the \n",
    "    cut-off have been attenuated. This is done using a Lanczos filter. The \n",
    "    filter works on any dimensional data, as long as the filtering dimension \n",
    "    is along axis=-1.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : numpy.ndarray\n",
    "        The data to be filtered.\n",
    "    cut : float\n",
    "        The frequency cut-off. All frequencies below 'cut' are attenuated.\n",
    "    n_points : int\n",
    "        The number of weights to use in the Lanczos filter. Must be odd.\n",
    "    fs : float\n",
    "        The sampling frequency of the data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data_filtered : numpy.ndarray\n",
    "        The filtered data.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # 2n-1 total weights\n",
    "    n = int((order + 1) / 2)\n",
    "\n",
    "    # Define the nyquist frequency\n",
    "    nyq = 0.5 * fs\n",
    "\n",
    "    # Define the range of the filter\n",
    "    k = np.arange(1, n, 1)\n",
    "\n",
    "    # Calculate the Lanczos sigma factor\n",
    "    sigma = np.empty((order))\n",
    "    sigma[n:] = np.sinc(2 * k * nyq * fs / n)\n",
    "    sigma[: n - 1] = np.sinc(2 * k[::-1] * nyq * fs / n)\n",
    "    sigma[n - 1] = np.sinc(0)\n",
    "\n",
    "    # Calculate the ideal response factor\n",
    "    w = np.empty((order))\n",
    "    w[n:] = -np.sin(2.0 * np.pi * cut * k) / (np.pi * k)\n",
    "    w[: n - 1] = -np.sin(2.0 * np.pi * cut * k[::-1]) / (np.pi * k[::-1])\n",
    "    w[n - 1] = 1 - (2 * cut)\n",
    "\n",
    "    # Combine the effects of the ideal response factor and the Lanczos factor\n",
    "    w_bar = w * sigma\n",
    "\n",
    "    # Filter the data along axis=-1\n",
    "    data_filtered = np.apply_along_axis(\n",
    "        lambda m: np.convolve(m, w_bar, mode=\"same\"), axis=-1, arr=data\n",
    "    )\n",
    "\n",
    "    return data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1425822e-b11e-4988-8684-a8967d2af350",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lanczos_bandpass_filter(data, lowcut, highcut, fs, filter_axis, order=101):\n",
    "    \"\"\"\n",
    "    This function returns a filtered signal in which all frqeuencies outside \n",
    "    the cut-off range have been attenuated. This is done using a Lanczos filter.\n",
    "    The filter works on any dimensional data, as long as the filtering \n",
    "    dimension is along axis=-1.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : numpy.ndarray\n",
    "        The data to be filtered.\n",
    "    lowcut : float\n",
    "        The low frequency cut-off. All frequencies below 'lowcut' \n",
    "        are attenuated\n",
    "    highcut : float\n",
    "        The high frequency cut-off. All frequencies above 'highcut' \n",
    "        are attenuated\n",
    "    fs : float\n",
    "        The sampling frequency of the data.\n",
    "    order : int\n",
    "        The number of weights to use in the Lanczos filter. Must be odd.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data_filtered : numpy.ndarray\n",
    "        The filtered data.\n",
    "    \"\"\"\n",
    "\n",
    "    # 2n-1 total weights\n",
    "    n = int((order + 1) / 2)\n",
    "\n",
    "    # Define the nyquist frequency\n",
    "    nyq = 0.5 * fs\n",
    "\n",
    "    # Define the range of the filter\n",
    "    k = np.arange(1, n, 1)\n",
    "\n",
    "    # Calculate the Lanczos sigma factor\n",
    "    # Calculate the Lanczos sigma factor\n",
    "    sigma = np.empty((order))\n",
    "    sigma[n:] = np.sinc(2 * k * nyq * fs / n)\n",
    "    sigma[: n - 1] = np.sinc(2 * k[::-1] * nyq * fs / n)\n",
    "    sigma[n - 1] = np.sinc(0)\n",
    "\n",
    "    # Calculate the ideal response factor\n",
    "    w = np.empty((order))\n",
    "    w[n:] = np.sin(2.0 * np.pi * highcut * k) / (np.pi * k) - np.sin(\n",
    "        2.0 * np.pi * lowcut * k\n",
    "    ) / (np.pi * k)\n",
    "    w[: n - 1] = np.sin(2.0 * np.pi * highcut * k[::-1]) / (np.pi * k[::-1]) - np.sin(\n",
    "        2.0 * np.pi * lowcut * k[::-1]\n",
    "    ) / (np.pi * k[::-1])\n",
    "    w[n - 1] = 2 * (highcut - lowcut)\n",
    "\n",
    "    # Combine the effects of the ideal response factor and the Lanczos factor\n",
    "    w_bar = w * sigma\n",
    "\n",
    "    # Filter the data along axis=-1\n",
    "    data_filtered = np.apply_along_axis(\n",
    "        lambda m: np.convolve(m, w_bar, mode=\"same\"), axis=filter_axis, arr=data\n",
    "    )\n",
    "\n",
    "    return data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64734ac5-84a4-4853-b919-a1457417d723",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fft_lowpass_filter(data, cut, fs):\n",
    "\n",
    "    data_fft = np.fft.fft(data, axis=-1)\n",
    "    frequencies = np.fft.fftfreq(data_fft.shape[-1], 1 / fs)\n",
    "\n",
    "    if np.size(data_fft.shape) == 1:\n",
    "        data_fft[np.abs(frequencies) <= cut] = 0\n",
    "    elif np.size(data_fft.shape) == 2:\n",
    "        data_fft[:, np.abs(frequencies) <= cut] = 0\n",
    "    elif np.size(data_fft.shape) == 3:\n",
    "        data_fft[:, :, np.abs(frequencies) <= cut] = 0\n",
    "    else:\n",
    "        print(\"Data must be 1D, 2D, or 3D\")\n",
    "    data_filtered = np.real(np.fft.ifft(data_fft, axis=-1))\n",
    "\n",
    "    return data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ed4095b-c7c8-4f6f-aa22-4ae3d25827f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fft_highpass_filter(data, cut, fs):\n",
    "\n",
    "    data_fft = np.fft.fft(data, axis=-1)\n",
    "    frequencies = np.fft.fftfreq(data_fft.shape[-1], 1 / fs)\n",
    "\n",
    "    if np.size(data_fft.shape) == 1:\n",
    "        data_fft[np.abs(frequencies) >= cut] = 0\n",
    "    elif np.size(data_fft.shape) == 2:\n",
    "        data_fft[:, np.abs(frequencies) >= cut] = 0\n",
    "    elif np.size(data_fft.shape) == 3:\n",
    "        data_fft[:, :, np.abs(frequencies) >= cut] = 0\n",
    "    else:\n",
    "        print(\"Data must be 1D, 2D, or 3D\")\n",
    "    data_filtered = np.real(np.fft.ifft(data_fft, axis=-1))\n",
    "\n",
    "    return data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8de36681-a4b9-43b6-b9f3-f10ef092a56f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fft_bandpass_filter(data, lowcut, highcut, fs):\n",
    "\n",
    "    data_fft = np.fft.fft(data, axis=-1)\n",
    "    frequencies = np.fft.fftfreq(data_fft.shape[-1], 1 / fs)\n",
    "\n",
    "    if np.size(data_fft.shape) == 1:\n",
    "        data_fft[(np.abs(frequencies) <= lowcut) | (np.abs(frequencies) >= highcut)] = 0\n",
    "    elif np.size(data_fft.shape) == 2:\n",
    "        data_fft[\n",
    "            :, (np.abs(frequencies) <= lowcut) | (np.abs(frequencies) >= highcut)\n",
    "        ] = 0\n",
    "    elif np.size(data_fft.shape) == 3:\n",
    "        data_fft[\n",
    "            :, :, (np.abs(frequencies) <= lowcut) | (np.abs(frequencies) >= highcut)\n",
    "        ] = 0\n",
    "    else:\n",
    "        print(\"Data must be 1D, 2D, or 3D\")\n",
    "    data_filtered = np.real(np.fft.ifft(data_fft, axis=-1))\n",
    "\n",
    "    return data_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e1b71b-30ab-4bac-ad2b-6cfc0192caca",
   "metadata": {},
   "source": [
    "## EOF Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ccde4098-0a9e-42f6-b55e-fe62f1ce2842",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_before_ceof(u850_f_merave, u200_f_merave, olr_f_merave):  # (time,lon)\n",
    "    # normalize the data before doing eof,\n",
    "    # you need to do this because the unit of the two dataset is not the same\n",
    "    u850_f_merave = np.transpose(u850_f_merave)\n",
    "    u200_f_merave = np.transpose(u200_f_merave)\n",
    "    olr_f_merave = np.transpose(olr_f_merave)\n",
    "    nlon = np.size(u850_f_merave, 0)\n",
    "    nt = np.size(u850_f_merave, 1)\n",
    "\n",
    "    mu_u850 = np.nanmean(u850_f_merave)\n",
    "    std_u850 = np.nanstd(u850_f_merave)\n",
    "    u850_norm = (u850_f_merave - mu_u850) / std_u850\n",
    "\n",
    "    mu_u200 = np.nanmean(u200_f_merave)\n",
    "    std_u200 = np.nanstd(u200_f_merave)\n",
    "    u200_norm = (u200_f_merave - mu_u200) / std_u200\n",
    "\n",
    "    mu_olr = np.nanmean(olr_f_merave)\n",
    "    std_olr = np.nanstd(olr_f_merave)\n",
    "    olr_norm = (olr_f_merave - mu_olr) / std_olr\n",
    "\n",
    "    X = np.zeros([nlon * 3, nt])\n",
    "    X[0:nlon, :] = u850_norm\n",
    "    X[nlon : 2 * nlon, :] = u200_norm\n",
    "    X[2 * nlon : 3 * nlon, :] = olr_norm\n",
    "    return X, mu_u850, std_u850, mu_u200, std_u200, mu_olr, std_olr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd7f6468-5db7-4f71-8880-3d893433985c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eof(xx):  # x=x(structure dim, sampling dim)\n",
    "    u, s, v = np.linalg.svd(xx, full_matrices=False)\n",
    "    EOF = np.transpose(u)  # EOFi=EOF[i-1] EOF1=EOF[0],EOF2=EOF[1],....\n",
    "    PC = np.matmul(np.transpose(u), xx)  # PCi =pc[i-1], pc1=pc[0],pc2=pc[1],...\n",
    "    nt = np.size(xx, 1)\n",
    "    eigval = s ** 2 / nt\n",
    "    eigval_explained_var = eigval / np.sum(eigval) * 100  # percent\n",
    "\n",
    "    # calculate degree of freedom so that we can do North test\n",
    "    L = 1  # one-lag auto-corelation\n",
    "    B = 0\n",
    "    for k in range(L - 1, nt - L):\n",
    "        B = B + np.sum(xx[:, k] * xx[:, k + L])\n",
    "    phi_L = 1 / (nt - 2 * L) * B\n",
    "    phi_0 = 1 / nt * np.sum(xx ** 2)\n",
    "    r_L = phi_L / phi_0\n",
    "    # r_L     = np.nanmean(phi_L)/np.nanmean(phi_0)\n",
    "    dof = (1 - r_L ** 2) / (1 + r_L ** 2) * nt\n",
    "\n",
    "    eigval_err = eigval_explained_var * np.sqrt(2 / dof)\n",
    "    return EOF, PC, eigval, eigval_explained_var, eigval_err, dof, phi_0, phi_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b5d55da-8873-4d16-bec6-4747d85a4533",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eof(xx):  # x=x(structure dim, sampling dim)\n",
    "    u, s, v = np.linalg.svd(xx, full_matrices=False)\n",
    "    EOF = np.transpose(u)  # EOFi=EOF[i-1] EOF1=EOF[0],EOF2=EOF[1],....\n",
    "    PC = np.matmul(np.transpose(u), xx)  # PCi =pc[i-1], pc1=pc[0],pc2=pc[1],...\n",
    "    nt = np.size(xx, 1)\n",
    "    eigval = s ** 2 / nt\n",
    "    eigval_explained_var = eigval / np.sum(eigval) * 100  # percent\n",
    "\n",
    "    # calculate degree of freedom so that we can do North test\n",
    "    L = 1  # one-lag auto-corelation\n",
    "    B = 0\n",
    "    for k in range(L - 1, nt - L):\n",
    "        B = B + np.sum(xx[:, k] * xx[:, k + L])\n",
    "    phi_L = 1 / (nt - 2 * L) * B\n",
    "    phi_0 = 1 / nt * np.sum(xx ** 2)\n",
    "    r_L = phi_L / phi_0\n",
    "    # r_L     = np.nanmean(phi_L)/np.nanmean(phi_0)\n",
    "    dof = (1 - r_L ** 2) / (1 + r_L ** 2) * nt\n",
    "\n",
    "    eigval_err = eigval_explained_var * np.sqrt(2 / dof)\n",
    "    return EOF, PC, eigval, eigval_explained_var, eigval_err, dof, phi_0, phi_L\n",
    "\n",
    "\n",
    "def rmm_eight_phase_index(rmm1, rmm2, time_f, rmm1_ann, rmm2_ann):\n",
    "    rmm1_norm = (rmm1 - np.mean(rmm1_ann)) / np.std(rmm1_ann)  # normalized rmm1\n",
    "    rmm2_norm = (rmm2 - np.mean(rmm2_ann)) / np.std(rmm2_ann)  # normalized rmm2\n",
    "    n = np.zeros(9)\n",
    "    RMM_ind = np.empty((9, np.size(time_f)))\n",
    "    RMM_ind[:] = np.NaN\n",
    "    for i in range(0, np.size(time_f)):\n",
    "        n = n.astype(int)\n",
    "        RMM1 = rmm1_norm[i]\n",
    "        RMM2 = rmm2_norm[i]\n",
    "        A = RMM1 ** 2 + RMM2 ** 2\n",
    "        if (A < 1).any():  # weak MJO\n",
    "            RMM_ind[8, n[8]] = i\n",
    "            n[8] = n[8] + 1\n",
    "        elif RMM1 < 0 and RMM2 < 0 and np.abs(RMM1) > np.abs(RMM2):  # PHASE1\n",
    "            RMM_ind[0, n[0]] = i\n",
    "            n[0] = n[0] + 1\n",
    "        elif RMM1 < 0 and RMM2 < 0 and np.abs(RMM1) < np.abs(RMM2):  # 2\n",
    "            RMM_ind[1, n[1]] = i\n",
    "            n[1] = n[1] + 1\n",
    "        elif RMM1 > 0 and RMM2 < 0 and np.abs(RMM1) < np.abs(RMM2):  # 3\n",
    "            RMM_ind[2, n[2]] = i\n",
    "            n[2] = n[2] + 1\n",
    "        elif RMM1 > 0 and RMM2 < 0 and np.abs(RMM1) > np.abs(RMM2):  # 4\n",
    "            RMM_ind[3, n[3]] = i\n",
    "            n[3] = n[3] + 1\n",
    "        elif RMM1 > 0 and RMM2 > 0 and np.abs(RMM1) > np.abs(RMM2):  # 5\n",
    "            RMM_ind[4, n[4]] = i\n",
    "            n[4] = n[4] + 1\n",
    "        elif RMM1 > 0 and RMM2 > 0 and np.abs(RMM1) < np.abs(RMM2):  # 6\n",
    "            RMM_ind[5, n[5]] = i\n",
    "            n[5] = n[5] + 1\n",
    "        elif RMM1 < 0 and RMM2 > 0 and np.abs(RMM1) < np.abs(RMM2):  # 7\n",
    "            RMM_ind[6, n[6]] = i\n",
    "            n[6] = n[6] + 1\n",
    "        elif RMM1 < 0 and RMM2 > 0 and np.abs(RMM1) > np.abs(RMM2):  # 8\n",
    "            RMM_ind[7, n[7]] = i\n",
    "            n[7] = n[7] + 1\n",
    "    return n, RMM_ind, rmm1_norm, rmm2_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3e90595-70d3-467a-9f3e-e874db156ce7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eight_phase_composite(x_f, RMM_ind):\n",
    "    x_f_8ph = np.zeros([8, np.size(x_f, 1), np.size(x_f, 2)])\n",
    "    for ph in range(0, 8):\n",
    "        i = np.squeeze(np.argwhere(~np.isnan(RMM_ind[ph, :])))\n",
    "        ii = RMM_ind[ph, i]\n",
    "        ii = ii.astype(int)\n",
    "        x_f_8ph[ph, :, :] = np.mean(x_f[ii, :, :], 0)\n",
    "    return x_f_8ph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044090c8-ced4-4a49-9b2f-c74b6dec2683",
   "metadata": {},
   "source": [
    "# Miscellaneous Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a6e7368-2443-4f4e-86bc-ebe0d3146365",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def modified_colormap(colormap, central_color, central_width, blend_strength):    \n",
    "    '''\n",
    "    This function modifies a colormap to set the central region to be white. \n",
    "    Within the region specified by the 'width' parameter, the colormap is blended towards white using a linspace.\n",
    "    \n",
    "    Parameters:\n",
    "        colormap (str): The name of an existing matplotlib colormap\n",
    "        central_width (float): The width of the region to be set to white\n",
    "        blend_strength (float): The width of the regions to be blended to white\n",
    "\n",
    "    Returns:\n",
    "        modified_colormap (matplotlib.colors.LinearSegmentedColormap): The modified colormap\n",
    "    \n",
    "    '''\n",
    "    # Import libraries\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib import colors as mcolors\n",
    "    \n",
    "    try:\n",
    "        c = mcolors.cnames[central_color]\n",
    "    except: \n",
    "        raise KeyError('Not a matplotlib named color')\n",
    "        \n",
    "    central_color = list(mcolors.to_rgba(central_color))\n",
    "    \n",
    "    # Raise an error if the width is not between 0 and 1\n",
    "    if ((central_width < 0)+(central_width > 1)):\n",
    "        raise ValueError('Central width must be in range [0, 1]')\n",
    "    elif ((blend_strength < 0) + (blend_strength > 1)):\n",
    "        raise ValueError('Blend strength must be in range [0, 1]')\n",
    "    \n",
    "    # Convert the widths to the range [0, 127]\n",
    "    else:             \n",
    "        central_width = int(127*central_width)\n",
    "        blend_strength = int(blend_strength*(127-central_width))\n",
    "\n",
    "    # Get the colormap values\n",
    "    original_colormap = plt.cm.get_cmap(colormap)\n",
    "    newcolors = original_colormap(np.linspace(0, 1, 256))\n",
    "    \n",
    "    # Get the value of the colormap 'width' values left of the center, and blend from that value to white at the center\n",
    "    newcolors[128-central_width-blend_strength:128-central_width, :] = np.linspace(\n",
    "        newcolors[128-central_width-blend_strength, :], \n",
    "        central_color, \n",
    "        blend_strength\n",
    "    )\n",
    "    \n",
    "    newcolors[128-central_width:128+central_width, :] = central_color\n",
    "    \n",
    "    # Get the value of the colormap 'width' values right of the center, and blend from white at the center to that value\n",
    "    newcolors[128+central_width:128+central_width+blend_strength, :] = np.linspace(\n",
    "        central_color,\n",
    "        newcolors[128+central_width+blend_strength, :], \n",
    "        blend_strength\n",
    "    )\n",
    "    \n",
    "    # Create a new colormap object from the modified map\n",
    "    modified_colormap = mcolors.LinearSegmentedColormap.from_list(colormap+'_modified', newcolors)\n",
    "    \n",
    "    return modified_colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b71ea16-b233-427b-b997-127df23905cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parabolic_cylinder_function(y, order):\n",
    "    from scipy import special\n",
    "    poly = special.hermite(order)\n",
    "    return poly(y)*np.exp(-y**2/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd1cb1e9-9e1e-472c-b08e-5de8b91b1556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tick_labeller(ticks, direction, degree_symbol=True):\n",
    "    label = []\n",
    "    for i in range(len(ticks)):\n",
    "        if degree_symbol == True:\n",
    "            if direction=='lon':\n",
    "                if ticks[i] == 0 or np.abs(ticks[i]) >= 180: \n",
    "                    label.append(f\"{np.abs(ticks[i]):.0f}°\")\n",
    "                elif ticks[i] < 0:\n",
    "                    label.append(f\"{np.abs(ticks[i]):.0f}°W\")\n",
    "                elif ticks[i] > 0:\n",
    "                    label.append(f\"{np.abs(ticks[i]):.0f}°E\")\n",
    "            elif direction=='lat':\n",
    "                if ticks[i] == 0:\n",
    "                    label.append(f\"{np.abs(ticks[i]):.0f}°\")\n",
    "                elif ticks[i] < 0:\n",
    "                    label.append(f\"{np.abs(ticks[i]):.0f}°S\")\n",
    "                elif ticks[i] > 0:\n",
    "                    label.append(f\"{np.abs(ticks[i]):.0f}°N\")\n",
    "        else:\n",
    "            if direction=='lon':\n",
    "                if ticks[i] == 0 or np.abs(ticks[i]) >= 180: \n",
    "                    label.append(f\"{np.abs(ticks[i]):.0f}\")\n",
    "                elif ticks[i] < 0:\n",
    "                    label.append(f\"{np.abs(ticks[i]):.0f}W\")\n",
    "                elif ticks[i] > 0:\n",
    "                    label.append(f\"{np.abs(ticks[i]):.0f}E\")\n",
    "            elif direction=='lat':\n",
    "                if ticks[i] == 0:\n",
    "                    label.append(f\"{np.abs(ticks[i]):.0f}\")\n",
    "                elif ticks[i] < 0:\n",
    "                    label.append(f\"{np.abs(ticks[i]):.0f}S\")\n",
    "                elif ticks[i] > 0:\n",
    "                    label.append(f\"{np.abs(ticks[i]):.0f}N\")\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1628de9c-6435-4b91-a9c9-94fcf4d2685e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
